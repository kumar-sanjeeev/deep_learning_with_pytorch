{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_linearRegression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementaion of Linear Regression using Pytorch\n",
        "\n",
        "### Problem Statement:\n",
        "Create a model that predicts crop yields for apples and oranges (target variables) by looking at the average temperature, rainfall, and humidity (input variables or features) in a region. \n",
        "\n",
        "*   ***Approach 1*** : will implement the linear regression using self defined linear regression model, loss function (least mean square) and optimizer (gradient descent).\n",
        "*   ***Approach 2***: will implement the linear regression by complete use of pytorch library.\n",
        "\n"
      ],
      "metadata": {
        "id": "tY7VoRxkTqhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Approach 1"
      ],
      "metadata": {
        "id": "n8UO37Q2-vzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "SX_12Ey2UW31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Data\n",
        "input_data =  np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Output Apple and Orange crop yield\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119]], dtype='float32')"
      ],
      "metadata": {
        "id": "8QK13v1QUil1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the numpy data into torch tensor\n",
        "input_data = torch.from_numpy(input_data)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(input_data)\n",
        "print(targets)"
      ],
      "metadata": {
        "id": "T0MiV54ZUh22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few important points regarding linear regression\n",
        "\n",
        "\n",
        "*   In linear regression each target variable is estimated to be weighted sum of the input features/variables, offset by constant term called bias.\n",
        "*   **Learning Part** of linear regression is to find out the weight and bias term using the training data so that accurate predications can be made for new data point.\n",
        "\n",
        "*   Adjustment of weights will be done using the optimization technique called **gradient descent**. To apply gradient descent, first will calculate the loss function that determines how well our model is performing.\n",
        "\n",
        "* **In case of mean squared error loss, loss is a quadratic function of our weights and biases, and our objective is to find the set of weights where the loss is the lowest.***"
      ],
      "metadata": {
        "id": "WgdK6PoXWg-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the weight and bias matrix for model\n",
        "# intially we will pick the random value for weight and bias terms\n",
        "weight = torch.randn((2,3), requires_grad=True)\n",
        "bias = torch.randn(2, requires_grad=True)\n",
        "print(weight)\n",
        "print(bias)"
      ],
      "metadata": {
        "id": "Zh-nB_ybVzbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# formula for  linear regression model is\n",
        "# y = W.transpose * X  + B\n",
        "def linear_regression_model(inputs):\n",
        "  return inputs @ weight.t() + bias\n"
      ],
      "metadata": {
        "id": "aTL9drH8Z0oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the mean squared loss function\n",
        "\n",
        "def mean_squared_loss(preds, target):\n",
        "  diff = preds - target\n",
        "  sq_diff_sum = torch.sum(diff*diff)\n",
        "  avg_loss = sq_diff_sum/diff.numel()\n",
        "\n",
        "  return avg_loss"
      ],
      "metadata": {
        "id": "yKGklBAFaeyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Main algorithm\n",
        "# This is an iterative algorithm and we will updates till the point where we able to achieve the minimum loss.\n",
        "no_of_epochs = 160\n",
        "learning_rate = 1e-5\n",
        "\n",
        "for epoch in range(no_of_epochs):\n",
        "  pred = linear_regression_model(input_data)\n",
        "  loss = mean_squared_loss(pred, targets)\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    weight -= weight.grad * learning_rate\n",
        "    bias -= bias.grad * learning_rate\n",
        "    weight.grad.zero_()\n",
        "    bias.grad.zero_()\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print('Epoch[{}/{}], Loss:{:.4f}'.format(epoch+1, no_of_epochs, loss))\n"
      ],
      "metadata": {
        "id": "02ew70TI2VKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Approach 2"
      ],
      "metadata": {
        "id": "tjg1BLg8-0ZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n"
      ],
      "metadata": {
        "id": "lMtApr8L-3Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70], \n",
        "                   [74, 66, 43], \n",
        "                   [91, 87, 65], \n",
        "                   [88, 134, 59], \n",
        "                   [101, 44, 37], \n",
        "                   [68, 96, 71], \n",
        "                   [73, 66, 44], \n",
        "                   [92, 87, 64], \n",
        "                   [87, 135, 57], \n",
        "                   [103, 43, 36], \n",
        "                   [68, 97, 70]], \n",
        "                  dtype='float32')\n",
        "\n",
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119],\n",
        "                    [57, 69], \n",
        "                    [80, 102], \n",
        "                    [118, 132], \n",
        "                    [21, 38], \n",
        "                    [104, 118], \n",
        "                    [57, 69], \n",
        "                    [82, 100], \n",
        "                    [118, 134], \n",
        "                    [20, 38], \n",
        "                    [102, 120]], \n",
        "                   dtype='float32')"
      ],
      "metadata": {
        "id": "rkAtKnDA_eNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting the data into the tensor\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)"
      ],
      "metadata": {
        "id": "1zfIpw-N_ivq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we will use the TENSORDATASET from pytorch utilis, which help us to access the rows from inputs and targets as tuples. \n",
        "# First element of tuple provide input variables for the selected rows and the second element gives the targets lables/values\n",
        "\n",
        "train_ds = TensorDataset(inputs, targets)"
      ],
      "metadata": {
        "id": "22-MUe97_x32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATALOADER is used to split the training data that we got from Tensordataset into the predefined batch size. \n",
        "batch_size = 5\n",
        "train_batch = DataLoader(train_ds, batch_size, shuffle = True)"
      ],
      "metadata": {
        "id": "Fvl6Fu9xBRIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "# we can define the linear model using nn.linear function of pytorch. It will automatically create the weight and bias matrix. \n",
        "# Inputs given: no of Input features, no of target outputs\n",
        "\n",
        "model = nn.Linear(3,2)\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "metadata": {
        "id": "ZePAiLJiBs-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function \n",
        "import torch.nn.functional as F\n",
        "\n",
        "loss_function = F.mse_loss # mean squared loss"
      ],
      "metadata": {
        "id": "bP_1JQQBCVEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer\n",
        "# Inputs : model parameters (i.e weight and bias matrix and learning rate)\n",
        "learning_rate = 1e-5\n",
        "opt = torch.optim.SGD(model.parameters(), learning_rate)\n"
      ],
      "metadata": {
        "id": "NGMZVeSpCmOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define training_function\n",
        "\n",
        "def train_model (num_epoch, model, loss_fn, opt, train_batch):\n",
        "\n",
        "  for epoch in range(num_epoch):\n",
        "    \n",
        "    # Taking the input and target data from defined batch\n",
        "    for input, target in train_batch:\n",
        "      \n",
        "      # Generating Model predication\n",
        "      pred = model(input)\n",
        "\n",
        "      # Calculating loss\n",
        "      loss = loss_fn(pred, target)\n",
        "\n",
        "      # Computing gradients\n",
        "      loss.backward()\n",
        "\n",
        "      # updating the model parameters (weight and bias) using optimizer\n",
        "      opt.step()\n",
        "\n",
        "      # equating the model parameters gradients equal to zero for next epoch\n",
        "      opt.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "      # print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epoch, loss.item()))\n",
        "      print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epoch, loss))\n"
      ],
      "metadata": {
        "id": "IPVRbog5DRPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(100, model, loss_function, opt, train_batch)"
      ],
      "metadata": {
        "id": "rMPIfWLxFYAy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}